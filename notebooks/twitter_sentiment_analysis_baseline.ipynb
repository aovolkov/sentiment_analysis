{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter_sentiment_analysis_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RX_ZDhicpHkV"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aovolkov/sentiment_analysis/blob/main/notebooks/twitter_sentiment_analysis_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNKaJz5j_ylj"
      },
      "source": [
        "# Подбор baseline для задачи определения тональности твитов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "## Установка библиотек"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JAEdOLqA39Y",
        "outputId": "a3b8d5c3-02c4-4d05-90d6-aad67f6e0f88"
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
            "\r\u001b[K     |██████                          | 10kB 16.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20kB 11.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 30kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 40kB 8.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 51kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 4.7MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok002ceNB8E7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "156ed0fb-cdb0-448e-e2bb-0ee0cb51d05c"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from string import punctuation\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, f1_score, roc_auc_score\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "## Загрузка данных\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B4iBoQ_cM9u"
      },
      "source": [
        "Для данной задачи был выбран датасет с разметкой сентимента русскоязычных твитов (подробнее про него в [статье](http://www.swsys.ru/index.php?page=article&id=3962&lang=)). Корпус твитов содержит 114,911 положительных и 111,923 отрицательных записей. Загрузить его можно [тут](https://study.mokoron.com/).\n",
        "\n",
        "Так как данный датасет не принадлежит к какой-то конкретной категории (отзывы на фильмы, отзывы на продукты и т.д.), то он должен прекрасно подходить под выявление неких общих закономерностей свойственных задаче sentiment analysis.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_amNUPtdJL1",
        "outputId": "416c2eb3-7b04-458f-fc6e-b926950e19ec"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dher3ozucM9u"
      },
      "source": [
        "negative_texts = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Projects/Sentiment/negative_twitter.csv', encoding='utf8', sep=';', header=None)\n",
        "positive_texts = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Projects/Sentiment/positive_twitter.csv', encoding='utf8', sep=';', header=None)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "JjdavurUcM9u",
        "scrolled": true,
        "outputId": "c7eeaeee-45d4-4d24-a751-34dee563da0c"
      },
      "source": [
        "positive_texts.sample(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>45225</th>\n",
              "      <td>409983419545055232</td>\n",
              "      <td>1386582639</td>\n",
              "      <td>Mer1990S</td>\n",
              "      <td>Уходит № 5 / Герой  не армянин )))) !!! Следую...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>50822</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41554</th>\n",
              "      <td>409932763077554176</td>\n",
              "      <td>1386570561</td>\n",
              "      <td>AnatoliyKurg</td>\n",
              "      <td>В Госпитале Ветеранов защита окон 80 Lvl - реш...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>876</td>\n",
              "      <td>73</td>\n",
              "      <td>123</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88893</th>\n",
              "      <td>410826246520442881</td>\n",
              "      <td>1386783584</td>\n",
              "      <td>VictoriaGoldSha</td>\n",
              "      <td>Завтра день самоуправления-_-5 уроков и все со...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>661</td>\n",
              "      <td>364</td>\n",
              "      <td>627</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58058</th>\n",
              "      <td>410128512259862528</td>\n",
              "      <td>1386617231</td>\n",
              "      <td>L_toutprix</td>\n",
              "      <td>@Denis_Shvedak ой, господи, кому чего, выражен...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5359</td>\n",
              "      <td>57</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38606</th>\n",
              "      <td>409886942520950784</td>\n",
              "      <td>1386559637</td>\n",
              "      <td>cikivyjakic</td>\n",
              "      <td>Возвключим же православный   Grinder в честь т...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>133</td>\n",
              "      <td>134</td>\n",
              "      <td>129</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       0           1                2   ...   9    10  11\n",
              "45225  409983419545055232  1386582639         Mer1990S  ...   53    0   0\n",
              "41554  409932763077554176  1386570561     AnatoliyKurg  ...   73  123   0\n",
              "88893  410826246520442881  1386783584  VictoriaGoldSha  ...  364  627   0\n",
              "58058  410128512259862528  1386617231       L_toutprix  ...   57   33   1\n",
              "38606  409886942520950784  1386559637      cikivyjakic  ...  134  129   0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSE9qQAFcM9u"
      },
      "source": [
        "sentences = np.concatenate([positive_texts[3].values, negative_texts[3].values])\n",
        "\n",
        "labels = [[1] for _ in range(positive_texts.shape[0])] + [[0] for _ in range(negative_texts.shape[0])]\n",
        "\n",
        "# проверка на длину \n",
        "assert len(sentences) == len(labels) == positive_texts.shape[0] + negative_texts.shape[0]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FC7I1PH3cM9u",
        "outputId": "9a430dc9-b007-403c-a4de-586c16dcf5d1"
      },
      "source": [
        "sentences[210000]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Шрамы от сладкого ;( p.s слабонервным не смотреть! http://t.co/kMoYf4vXqk'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFAuFmDdcM9u",
        "outputId": "b063e5d9-f44a-4dfb-ef07-bda7a35ef7c2"
      },
      "source": [
        "train_sentences, test_sentences, train_labels, test_labels = train_test_split(sentences, labels, test_size=0.2)\n",
        "train_sentences, valid_sentences, train_labels, valid_labels = train_test_split(train_sentences, train_labels, test_size=0.25)\n",
        "\n",
        "print('Размер тренировочной выборки:', len(train_labels))\n",
        "print('Размер валидационной выборки:', len(valid_labels))\n",
        "print('Размер тестовой выборки:', len(test_labels))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Размер тренировочной выборки: 136100\n",
            "Размер валидационной выборки: 45367\n",
            "Размер тестовой выборки: 45367\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGYk-zZnohy8"
      },
      "source": [
        "## Подбор Baseline "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNvTgd7D-Uko"
      },
      "source": [
        "### Подбор классификатора и векторайзера"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyWM-gc0oisB"
      },
      "source": [
        "def create_pipeline(vectorizer, classifier):\n",
        "    return Pipeline([('vectorizer', vectorizer), \n",
        "                     ('classifier', classifier)])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0klB8iRpuan",
        "outputId": "10f41224-8215-48db-e88a-dea4ce9069d2"
      },
      "source": [
        "%%time\n",
        "warnings.filterwarnings('ignore')\n",
        "list_of_algos = [LogisticRegression, LinearSVC, SGDClassifier,\n",
        "                 MultinomialNB, GradientBoostingClassifier]\n",
        "list_of_algos_str = ['LogisticRegression', 'LinearSVC', 'SGDClassifier',\n",
        "                 'MultinomialNB', ' GradientBoostingClassifier']\n",
        "\n",
        "tfidf_results = []\n",
        "countvect_results = []\n",
        "\n",
        "for clf, clf_str  in tqdm(zip(list_of_algos, list_of_algos_str)):\n",
        "    countvect_results.append(round(cross_val_score(create_pipeline(CountVectorizer(), clf()), valid_sentences, valid_labels).mean(), 5))\n",
        "    tfidf_results.append(round(cross_val_score(create_pipeline(TfidfVectorizer(), clf()), valid_sentences, valid_labels).mean(), 5))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5it [04:20, 52.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4min 22s, sys: 14.3 s, total: 4min 36s\n",
            "Wall time: 4min 20s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "nGBLJf4du01g",
        "outputId": "7c24eb1f-e94b-4e51-86bf-93da7f765ddf"
      },
      "source": [
        "results_table = pd.DataFrame({'CountVectorizer': countvect_results, 'TfidfVectorizer': tfidf_results}, index=list_of_algos_str)\n",
        "results_table"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CountVectorizer</th>\n",
              "      <th>TfidfVectorizer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.73192</td>\n",
              "      <td>0.72844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearSVC</th>\n",
              "      <td>0.71153</td>\n",
              "      <td>0.72687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGDClassifier</th>\n",
              "      <td>0.72837</td>\n",
              "      <td>0.71907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MultinomialNB</th>\n",
              "      <td>0.72608</td>\n",
              "      <td>0.72301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GradientBoostingClassifier</th>\n",
              "      <td>0.64935</td>\n",
              "      <td>0.64476</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             CountVectorizer  TfidfVectorizer\n",
              "LogisticRegression                   0.73192          0.72844\n",
              "LinearSVC                            0.71153          0.72687\n",
              "SGDClassifier                        0.72837          0.71907\n",
              "MultinomialNB                        0.72608          0.72301\n",
              " GradientBoostingClassifier          0.64935          0.64476"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVteZT_A-kWW"
      },
      "source": [
        "### Лемматизация + стоп-слова"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ooNANhv-vhf"
      },
      "source": [
        "# в контексте задачи анализа тнальности частица 'не' и слово 'хорошо'\n",
        "# являются достаточно важными\n",
        "\n",
        "russian_stopwords = stopwords.words(\"russian\")\n",
        "del russian_stopwords[135]\n",
        "del russian_stopwords[3]\n",
        "\n",
        "# убираем обращения по @ и все символы, кроме скобочек))\n",
        "TOKENIZE_RE = re.compile(r'@+[\\w\\d]*|[\\.\\^\\$\\*\\?\\{\\}\\[\\]\\|]+', re.I)\n",
        "\n",
        "morph = MorphAnalyzer()\n",
        "\n",
        "\n",
        "def preprocess_text(text):\n",
        "    prep_text = []\n",
        "    \n",
        "    for txt in text:\n",
        "        txt = txt.lower()\n",
        "        tokens = [morph.parse(token)[0].normal_form for token in txt.strip().split()\\\n",
        "          if token not in russian_stopwords\\\n",
        "          and TOKENIZE_RE.findall(token) == []]\n",
        "        txt = ' '.join(tokens)\n",
        "        prep_text.append(txt)\n",
        "    \n",
        "    return np.array(prep_text)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKaw16V8cxaV"
      },
      "source": [
        "valid_sentences_preprocesed = preprocess_text(valid_sentences) "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7fTDp70jXOT"
      },
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "tfidf_prepr_results = []\n",
        "countvect_prepr_results = []\n",
        "\n",
        "for clf, clf_str  in zip(list_of_algos, list_of_algos_str):\n",
        "    countvect_prepr_results.append(round(cross_val_score(create_pipeline(CountVectorizer(), clf()), valid_sentences_preprocesed, valid_labels).mean(), 5))\n",
        "    tfidf_prepr_results.append(round(cross_val_score(create_pipeline(TfidfVectorizer(), clf()), valid_sentences_preprocesed, valid_labels).mean(), 5))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "s2ubZ80uj4O2",
        "outputId": "5c96f456-e4eb-4faf-8766-3657ea7ae05a"
      },
      "source": [
        "results_table['CountVectorizer (preprocessed)'] = countvect_prepr_results\n",
        "results_table['TfidfVectorizer (preprocessed)'] = tfidf_prepr_results\n",
        "results_table\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CountVectorizer</th>\n",
              "      <th>TfidfVectorizer</th>\n",
              "      <th>CountVectorizer (preprocessed)</th>\n",
              "      <th>TfidfVectorizer (preprocessed)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.73192</td>\n",
              "      <td>0.72844</td>\n",
              "      <td>0.69985</td>\n",
              "      <td>0.70199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LinearSVC</th>\n",
              "      <td>0.71153</td>\n",
              "      <td>0.72687</td>\n",
              "      <td>0.68043</td>\n",
              "      <td>0.69149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGDClassifier</th>\n",
              "      <td>0.72837</td>\n",
              "      <td>0.71907</td>\n",
              "      <td>0.69861</td>\n",
              "      <td>0.69672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MultinomialNB</th>\n",
              "      <td>0.72608</td>\n",
              "      <td>0.72301</td>\n",
              "      <td>0.69875</td>\n",
              "      <td>0.69606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GradientBoostingClassifier</th>\n",
              "      <td>0.64935</td>\n",
              "      <td>0.64476</td>\n",
              "      <td>0.62947</td>\n",
              "      <td>0.63328</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             CountVectorizer  ...  TfidfVectorizer (preprocessed)\n",
              "LogisticRegression                   0.73192  ...                         0.70199\n",
              "LinearSVC                            0.71153  ...                         0.69149\n",
              "SGDClassifier                        0.72837  ...                         0.69672\n",
              "MultinomialNB                        0.72608  ...                         0.69606\n",
              " GradientBoostingClassifier          0.64935  ...                         0.63328\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM7ufWauqBhG"
      },
      "source": [
        "Качество после препроцессинга только ухудшилось. \n",
        "\n",
        "Наилучшее качество среди всех классификаторов показали LinearSVC и LogisticRegression. Остановимся на них.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59F2uYXonVp1"
      },
      "source": [
        "## Подбор параметров для Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETnNqmqWq3gO"
      },
      "source": [
        "def estimate(classifier, params_grid, scorer, data, labels):\n",
        "    pipeline = create_pipeline(TfidfVectorizer(), classifier)\n",
        "    grid_cv = RandomizedSearchCV(pipeline, params_grid, scoring=scorer, cv=5, \n",
        "                                 random_state=SEED, n_iter=100, verbose=1, n_jobs=-1)\n",
        "    grid_cv.fit(data, labels)\n",
        "    return grid_cv"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcPbKWw5naa5"
      },
      "source": [
        "# сетка для перебора параметров\n",
        "\n",
        "params_grid_vectorizer = {\n",
        "    'vectorizer__max_df': [0.85, 0.9, 0.95, 1.0],\n",
        "    'vectorizer__min_df': [1, 10, 20],\n",
        "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6),\n",
        "                               (2, 2), (2, 3), (2, 4), (3, 3), (3, 4)],\n",
        "    'vectorizer__stop_words': [russian_stopwords, None],\n",
        "    'vectorizer__norm': ['l1', 'l2'],\n",
        "    'vectorizer__smooth_idf': [True, False],\n",
        "    'vectorizer__use_idf': [True, False],\n",
        "    'vectorizer__sublinear_tf': [True, False]\n",
        "}\n",
        "\n",
        "params_grid_log_regr = {\n",
        "    'classifier__penalty': ['l1', 'l2', 'elasticnet'],\n",
        "    'classifier__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "    'classifier__max_iter': np.arange(100, 1000, 100),\n",
        "    'classifier__tol': [1e-5, 1e-4, 1e-3],\n",
        "    'classifier__C': np.arange(0.5, 5, 0.1)\n",
        "}\n",
        "\n",
        "params_grid_lsvc = {\n",
        "    'classifier__loss': ['hinge', 'squared_hinge'],\n",
        "    'classifier__max_iter': np.arange(100, 1000, 100),\n",
        "    'classifier__tol': [1e-5, 1e-4, 1e-3],\n",
        "    'classifier__C': np.arange(0.5, 1.2, 0.1)\n",
        "}"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5SVrb0HsJ2X"
      },
      "source": [
        "Подберем параметры для линейного SVM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL_pwbeBr4m2",
        "outputId": "59d17e13-a603-4f93-9a2e-63704b9f78ac"
      },
      "source": [
        "%%time\n",
        "grid_search_lsvc = estimate(LinearSVC(random_state=SEED), \n",
        "                                  {**params_grid_vectorizer, **params_grid_lsvc}, 'accuracy', valid_sentences, valid_labels)\n",
        "print(\"LinearSVC:\")\n",
        "print(f\"Лучшее качество - {grid_search_lsvc.best_score_}\")\n",
        "print(f\"Параметры - {grid_search_lsvc.best_params_}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 11.8min\n",
            "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed: 26.2min\n",
            "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 29.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LinearSVC:\n",
            "Лучшее качество - 0.7377389518625662\n",
            "Параметры - {'vectorizer__use_idf': False, 'vectorizer__sublinear_tf': True, 'vectorizer__stop_words': None, 'vectorizer__smooth_idf': False, 'vectorizer__norm': 'l2', 'vectorizer__ngram_range': (1, 2), 'vectorizer__min_df': 1, 'vectorizer__max_df': 0.85, 'classifier__tol': 1e-05, 'classifier__max_iter': 400, 'classifier__loss': 'hinge', 'classifier__C': 0.9999999999999999}\n",
            "CPU times: user 4min 45s, sys: 1.76 s, total: 4min 47s\n",
            "Wall time: 29min 26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKqm-nU09HqJ"
      },
      "source": [
        "Подберем параметры для линейного LogisticRegression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRxDcjGjvdpN",
        "outputId": "8db2e53f-3c70-4f5d-a402-9635f5b271b9"
      },
      "source": [
        "%%time\n",
        "grid_search_log_regr = estimate(LogisticRegression(random_state=SEED), \n",
        "                                  {**params_grid_vectorizer, **params_grid_log_regr}, 'accuracy', valid_sentences, valid_labels)\n",
        "print(\"LogisticRegression:\")\n",
        "print(f\"Лучшее качество - {grid_search_log_regr.best_score_}\")\n",
        "print(f\"Параметры - {grid_search_log_regr.best_params_}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 19.8min\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 29.9min\n",
            "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed: 57.0min\n",
            "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed: 64.2min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "Лучшее качество - 0.7331982734220932\n",
            "Параметры - {'vectorizer__use_idf': True, 'vectorizer__sublinear_tf': False, 'vectorizer__stop_words': None, 'vectorizer__smooth_idf': True, 'vectorizer__norm': 'l2', 'vectorizer__ngram_range': (1, 1), 'vectorizer__min_df': 1, 'vectorizer__max_df': 0.95, 'classifier__tol': 0.001, 'classifier__solver': 'saga', 'classifier__penalty': 'l2', 'classifier__max_iter': 600, 'classifier__C': 1.9999999999999996}\n",
            "CPU times: user 4min 37s, sys: 1.85 s, total: 4min 39s\n",
            "Wall time: 1h 4min 16s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlynBjHT2qQB"
      },
      "source": [
        "## Тренировка и тестирование модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_UweXLHOZpi"
      },
      "source": [
        "Linear SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh-kBF-i2eP2",
        "outputId": "4fdca30a-0632-492e-d63b-ce6d9ae92d8f"
      },
      "source": [
        "model_lvc = grid_search_lsvc.best_estimator_\n",
        "\n",
        "model_lvc.fit(train_sentences, train_labels)\n",
        "\n",
        "pred_labels_lvc = model_lvc.predict(test_sentences)\n",
        "\n",
        "print('Accuracy:', round(accuracy_score(pred_labels_lvc, test_labels), 4))\n",
        "print('F1 score:', round(f1_score(test_labels, pred_labels_lvc), 4))\n",
        "print('ROC AUC score:', round(roc_auc_score(test_labels, pred_labels_lvc), 4))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7705\n",
            "F1 score: 0.7761\n",
            "ROC AUC score: 0.7705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDAmK2eYOd_0"
      },
      "source": [
        "LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCjWKccn8qQY",
        "outputId": "cf2d8fcd-8d77-4817-945d-bfe17075dd6d"
      },
      "source": [
        "model_log_regr = grid_search_log_regr.best_estimator_\n",
        "\n",
        "model_log_regr.fit(train_sentences, train_labels)\n",
        "\n",
        "pred_labels_log_regr = model_log_regr.predict(test_sentences)\n",
        "\n",
        "print('Accuracy:', round(accuracy_score(pred_labels_log_regr, test_labels), 4))\n",
        "print('F1 score:', round(f1_score(test_labels, pred_labels_log_regr), 4))\n",
        "print('ROC AUC score:', round(roc_auc_score(test_labels, pred_labels_log_regr), 4))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7586\n",
            "F1 score: 0.7647\n",
            "ROC AUC score: 0.7585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkh7DPI9OPwt"
      },
      "source": [
        "### Примеры предсказаний моделей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIAKwIGmM5zy"
      },
      "source": [
        "Пример негативного твита"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ukk66gdaHvFz",
        "outputId": "fc5303cb-f9c1-440b-aa00-c6477ceedbd1"
      },
      "source": [
        "example_neg = ['Очень неприятный фильм!']\n",
        "print('Метка LVC:', model_lvc.predict(example_neg)[0])\n",
        "print('Вероятность LogisticRegression:', max(model_log_regr.predict_proba(example_neg)[0]))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Метка LVC: 0\n",
            "Вероятность LogisticRegression: 0.6304333918924427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3YAl68DNDDn"
      },
      "source": [
        "Пример неоднозначного твита"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxHp_zlQH6SB",
        "outputId": "712d60be-b771-4a44-ba8d-1dfa124cd298"
      },
      "source": [
        "example_neutral = ['Хорошо поиграли, жаль Витя ушел рано:(((']\n",
        "print('Метка LVC:', model_lvc.predict(example_neutral)[0])\n",
        "print('Метка LogisticRegression:', max(model_log_regr.predict_proba(example_neutral)[0]))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Метка LVC: 0\n",
            "Метка LogisticRegression: 0.7509092722396051\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy7chE-bNG8l"
      },
      "source": [
        "Пример позитивного твита"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyUJch5tOI5M",
        "outputId": "13c0f234-d894-4424-c929-cdb7ff079ecb"
      },
      "source": [
        "example_pos = ['Отлично провели время вместе!))']\n",
        "print('Метка LVC:', model_lvc.predict(example_pos)[0])\n",
        "print('Метка LogisticRegression:', max(model_log_regr.predict_proba(example_pos)[0]))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Метка LVC: 1\n",
            "Метка LogisticRegression: 0.9066715394614961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTYW5Ihp2unC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}