{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import re\n",
    "import codecs\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('Set2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный блокнот может служить baselin-ом в соревновании https://www.kaggle.com/c/morecomplicatedsentiment:\n",
    "\n",
    "> К вашей компании пришел заказчик, которому нужно решение задачи анализа тональности отзывов на товары. Заказчик хочет, чтобы вы оценили возможное качество работы такого алгоритма на небольшой тестовой выборке. При этом больше никаких данных вам не предоставляется.\n",
    "\n",
    ">Вам предстоит посмотреть на предоставленные заказчиком отзывы, собрать похожие отзывы в качестве обучающей выборки, и поэкспериментировать с постановкой задачи (разметкой вашей выборки на позитивные и негативные примеры) так, чтобы результат на примерах заказчика был по возможности получше.\n",
    "\n",
    ">Обратите внимание, что заказчик предоставил всего 100 примеров в качестве тестовой выборки - ситуация, когда размеченных данных почти нет - вообще очень частая в индустриальном анализе данных. Конечно, эти отзывы можно было бы идеально разметить вручную и получить максимальное качество, но вы сами не заинтересованы в таком подходе, т.к. потом придется и на всех новых примерах демонстрировать заказчику идеальную работу, что, конечно, вряд ли будет по силам алгоритму.\n",
    "\n",
    "Датасет для данной задачи был собран с Яндекс Маркета (https://market.yandex.ru/catalog--mobilnye-telefony/54726/list)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with codecs.open('morecomplicatedsentiment/test.csv', 'r') as file:\n",
    "    test_review = file.read()\n",
    "    parser = BeautifulSoup(test_review, 'html.parser')\n",
    "    test_reviews = parser.findAll('review')\n",
    "    test_review_list = [review.text for review in test_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(text, label):\n",
    "    try:\n",
    "        if label == 1:\n",
    "            text = re.findall(r'Достоинства(:.*?)Недостатки:', text)[0]\n",
    "        else:\n",
    "            text = re.findall(r'Недостатки(:.*?)Комментарий:', text)[0]\n",
    "        return re.sub(r'\\W', ' ', text)\n",
    "    except:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ужасно слабый аккумулятор, это основной минус ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ценанадежность-неубиваемостьдолго держит батар...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>подробнее в комментариях\\nК сожалению, факт по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>я любительница громкой музыки. Тише телефона у...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Дата выпуска - 2011 г, емкость - 1430 mAh, тех...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Ужасно слабый аккумулятор, это основной минус ...\n",
       "1  ценанадежность-неубиваемостьдолго держит батар...\n",
       "2  подробнее в комментариях\\nК сожалению, факт по...\n",
       "3  я любительница громкой музыки. Тише телефона у...\n",
       "4  Дата выпуска - 2011 г, емкость - 1430 mAh, тех..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame(test_review_list, columns=['text'])\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('morecomplicatedsentiment/train.json', orient='records', lines=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['label'] = train['rating'].apply(lambda x: int(x == 5))\n",
    "train['length'] = train['text'].apply(lambda x: len(x))\n",
    "train['text'] = train.apply(lambda x: extract_info(x['text'], x['label']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3320\n",
       "0    1680\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что выборка не сбалансирована."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 0 to 5004\n",
      "Data columns (total 4 columns):\n",
      "text      5000 non-null object\n",
      "rating    5000 non-null int64\n",
      "label     5000 non-null int64\n",
      "length    5000 non-null int64\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 195.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор классификатора\n",
    "Так как целевая переменная не сбалансирована, выберем только 1680 положительных отзывов в обучающую выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = shuffle(pd.concat([train[train['label'] == 0], \n",
    "                           train[train['label'] == 1].sort_values('length', ascending=False).head(1680)]), \n",
    "                           random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train['text'].values\n",
    "y = train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1680\n",
       "0    1680\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(vectorizer, transformer, classifier):\n",
    "    return Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('transformer', transformer),\n",
    "            ('classifier', classifier)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_estimator(classifier, params_grid, scorer, data, labels):\n",
    "    pipeline = make_pipeline(CountVectorizer(), TfidfTransformer(), classifier)\n",
    "    grid_cv = RandomizedSearchCV(pipeline, params_grid, scoring=scorer, cv=5, \n",
    "                                 random_state=777, n_iter=100, verbose=1, n_jobs=-1)\n",
    "    grid_cv.fit(data, labels)\n",
    "    return grid_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression - 0.9261904761904762\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(make_pipeline(CountVectorizer(), TfidfTransformer(), LogisticRegression(random_state=777, C=50)), X, y, cv=5).mean()\n",
    "print(f\"LogisticRegression - {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейный SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC - 0.9336309523809524\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(make_pipeline(CountVectorizer(), TfidfTransformer(), LinearSVC(random_state=777)), X, y, cv=5).mean()\n",
    "print(f\"LinearSVC - {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что LinearSVC показывает неммного лучшее качество. Попробуем настроить параметры для LinearSVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid_vectorizer = {\n",
    "    'vectorizer__max_df': [0.85, 0.9, 0.95, 1.0],\n",
    "    'vectorizer__min_df': [1, 10, 20],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6),\n",
    "                               (2, 2), (2, 3), (2, 4), (3, 3), (3, 4)],\n",
    "    'vectorizer__stop_words': [stop_words, None]\n",
    "}\n",
    "params_grid_transformer = {\n",
    "    'transformer__norm': ['l1', 'l2'],\n",
    "    'transformer__smooth_idf': [True, False],\n",
    "    'transformer__use_idf': [True, False],\n",
    "    'transformer__sublinear_tf': [True, False]\n",
    "}\n",
    "params_grid_lsvc = {\n",
    "    'classifier__loss': ['hinge', 'squared_hinge'],\n",
    "    'classifier__max_iter': np.arange(200, 1000, 100),\n",
    "    'classifier__tol': [1e-5, 1e-4, 1e-3],\n",
    "    'classifier__C': np.arange(0.5, 1.2, 0.1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC:\n",
      "Лучшее качество - 0.9348214285714286\n",
      "Параметры - {'vectorizer__stop_words': ['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между'], 'vectorizer__ngram_range': (1, 1), 'vectorizer__min_df': 1, 'vectorizer__max_df': 0.9, 'transformer__use_idf': True, 'transformer__sublinear_tf': True, 'transformer__smooth_idf': True, 'transformer__norm': 'l2', 'classifier__tol': 0.0001, 'classifier__max_iter': 300, 'classifier__loss': 'hinge', 'classifier__C': 0.6}\n",
      "CPU times: user 4.54 s, sys: 552 ms, total: 5.09 s\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_search_lsvc = make_estimator(LinearSVC(random_state=777), \n",
    "                                  {**params_grid_vectorizer, **params_grid_transformer, **params_grid_lsvc}, 'accuracy', X, y)\n",
    "print(\"LinearSVC:\")\n",
    "print(f\"Лучшее качество - {grid_search_lsvc.best_score_}\")\n",
    "print(f\"Параметры - {grid_search_lsvc.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Дефолтная LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = make_pipeline(CountVectorizer(), TfidfTransformer(), LogisticRegression(random_state=777)).fit(X, y).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission_lin_reg.csv', 'w') as f:\n",
    "    f.write(pd.DataFrame(pd.Series(map(str, range(0, 100))).str \\\n",
    "                         .cat(map(str, pd.Series(clf).apply(lambda x: 'neg' if x == 0 else 'pos')), sep=','), \n",
    "                         columns=['Id,y']).to_csv(sep=' ', index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Она дает результат порядка 0.944"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Настроенный LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_pipeline(CountVectorizer(), TfidfTransformer(), LinearSVC(random_state=777)).fit(X, y).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vectorizer',\n",
       "  CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                  dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                  lowercase=True, max_df=0.9, max_features=None, min_df=1,\n",
       "                  ngram_range=(1, 1), preprocessor=None,\n",
       "                  stop_words=['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с',\n",
       "                              'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его',\n",
       "                              'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы',\n",
       "                              'по', 'только', 'ее', 'мне', ...],\n",
       "                  strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                  tokenizer=None, vocabulary=None)),\n",
       " ('transformer',\n",
       "  TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=True, use_idf=True)),\n",
       " ('classifier',\n",
       "  LinearSVC(C=0.6, class_weight=None, dual=True, fit_intercept=True,\n",
       "            intercept_scaling=1, loss='hinge', max_iter=300, multi_class='ovr',\n",
       "            penalty='l2', random_state=777, tol=0.0001, verbose=0))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = grid_search_lsvc.best_estimator_\n",
    "svc.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = svc.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission_lin_svc.csv', 'w') as f:\n",
    "    f.write(pd.DataFrame(pd.Series(map(str, range(0, 100))).str \\\n",
    "                         .cat(map(str, pd.Series(pred).apply(lambda x: 'neg' if x == 0 else 'pos')), sep=','), \n",
    "                         columns=['Id,y']).to_csv(sep=' ', index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь уже результат получается порядка 0.955"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
